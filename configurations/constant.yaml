# 数据源类型  aishell_speech/libri_speech/life_speech
datasource_type: aishell_speech
# 模型类型
model_type: seq2seq


# 路径
path:
    # 模型保存路径
    model_path: ./models/bilstm


# 英文 LibriSpeech
libri_speech:
            #  数据集路径
            path: /home/wjunneng/Ubuntu/2019-Speech-Recognition/datasets/LibriSpeech/dev-clean
            # wav路径与label之间的分割符
            audio_label_splitter: ' '
            # 选中的txt数目
            how_many: 2

#中文 LifeSpeech
life_speech:
            # 数据集路径
            path: /home/wjunneng/Ubuntu/2019-Speech-Recognition/datasets/LifeSpeech
            # wav路径与label之间的分割符
            audio_label_splitter: ','
            # label文件路径
            audio_label_path: dev.txt
            # audio_index_pkl_path
            audio_index_pkl_path: audio_index.pkl

# 中文 aishellSpeech
aishell_speech:
              # 数据集路径
              path: /home/wjunneng/Ubuntu/Speech-Recognition/data/data_aishell
              # vocab size
              vocab_size: 4336
              # audio_index_pkl_path
              audio_index_pkl_path: audio_index.pkl
              # label文件路径
              audio_label_path: transcript/aishell_transcript_v0.8.txt
              # wav路径与label之间的分隔符
              audio_label_splitter: ' '

# token
token:
      PAD: 0
      UNK: 1
      SOS: 2
      EOS: 3
      SPACE: 4
      PAD_FLAG: '<pad>'
      UNK_FLAG: '<unk>'
      SOS_FLAG: '<sos>'
      EOS_FLAG: '<eos>'
      SPACE_FLAG: '<space>'
      # 组合
      flag_list: ['<pad>', '<unk>', '<sos>', '<eos>', '<space>']

## 模型参数
#num_layers_encoder: 2
#num_layers_decoder: 2
#rnn_size_encoder: 450
#rnn_size_decoder: 450
#embedding_dim: 10
#batch_size: 4
#epochs: 10
#use_cyclic_lr: True
#learning_rate: 0.00001
#max_lr: 0.00003
#learning_rate_decay_steps: 700

# seq2seq模型
seq2seq:
        # ########################## encoder
        # Low Frame Rate: number of frames to stack
        LFR_m: 4
        # Low Frame Rate: number of frames to skip
        LFR_n: 3
        # Dim of encoder input
        einput: 80
        # Size of encoder hidden units
        ehidden: 256
        # Number of encoder layers
        elayer: 3
        # Encoder dropout rate
        edropout: 0.2
        # Whether use bidirectional encoder
        ebidirectional: True
        # Type of encoder RNN
        etype: 'lstm'

        # ########################### attention
        # Type of attention (Only support Dot Product now)
        atype: 'dot'

        # ########################### decoder
        # Size of decoder embedding
        dembed: 512
        # Size of decoder hidden units, Should be encoder
        # (2*) hidden size dependding on bidirection
        dhidden: 512
        # Number of decoder layers.
        dlayer: 1

        # ############################ training config
        # number of maximum epochs
        epochs: 1
        # Halving learning rate when get small improvement
        half_lr: True
        # Early stop training when halving lr but still get small improvement
        early_stop: 0
        # Gradient norm threshold to clip
        max_norm: 5

        # ############################ minbatch
        # Batch size
        batch_size: 32
        # Batch size is reduced if the input sequence length > ML
        maxlen_in: 800
        # Batch size is reduced if the output sequence length > ML
        maxlen_out: 150
        # Number of workers to generate minibatch
        num_workers: 8

        # ############################ optimizer
        # Optimizer (support sgd and adam now) [sgd, adam]
        optimizer: adam
        # Init learning rate
        lr: 1e-3
        # Momentum for optimizer
        momentum: 0.0
        # weight decay (L2 penalty)
        l2: 1e-5
        # checkpoint
        checkpoint: None

        # ############################ other
        # how many times to print
        print_freq: 100






